{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Предобработка текста и классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитайте текст в файлах positive.txt и negative.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"positive.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    positive_plain = file.read()\n",
    "\n",
    "with open(\"negative.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    negative_plain = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(positive_plain[:400], negative_plain[:400], sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбейте данные на предложения\n",
    "\n",
    "Для токенизации используйте nltk.sent_tokenize. чтобы удалить имен пользователей из сообщений напишите регулярное выражение.\n",
    "\n",
    "<b>Классы символов в регулярных выражениях</b>:\n",
    "\n",
    "[A-Z] – символы верхнего регистра (латиница)\n",
    "\n",
    "[a-z] – символы нижнего регистра (латиница)\n",
    "\n",
    "[А-Я] – символы верхнего регистра (кириллица)\n",
    "\n",
    "[а-я] – символы нижнего регистра (кириллица)\n",
    "\n",
    "[0-9] или \\d – цифра\n",
    "\n",
    "[^0-9] или \\D – любой символ, кроме цифры\n",
    "\n",
    ". – Один любой символ, кроме новой строки \\n.\n",
    "\n",
    "? – 0 или 1 вхождение шаблона слева\n",
    "\n",
    "\\+ – 1 и более вхождений шаблона слева\n",
    "\n",
    "\\* – 0 и более вхождений шаблона слева\n",
    "\n",
    "\\w – Любая цифра или буква (\\W — все, кроме буквы или цифры)\n",
    "\n",
    "\\d – Любая цифра [0-9] (\\D — все, кроме цифры)\n",
    "\n",
    "\\s – Любой пробельный символ (\\S — любой непробельнй символ)\n",
    "\n",
    "\\b – Граница слова\n",
    "\n",
    "[..] – дин из символов в скобках ([^..] — любой символ, кроме тех, что в скобках)\n",
    "\n",
    "\\ – Экранирование специальных символов (\\. означает точку или \\+ — знак «плюс»)\n",
    "\n",
    "^ и $ – Начало и конец строки соответственно\n",
    "\n",
    "{n,m} – От n до m вхождений ({,m} — от 0 до m)\n",
    "\n",
    "a|b – Соответствует a или b\n",
    "\n",
    "() – Группирует выражение и возвращает найденный текст\n",
    "\n",
    "\\t, \\n, \\r – Символ табуляции, новой строки и возврата каретки соответственно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "\n",
    "def split_data(text):\n",
    "    # Избавляемся от имен пользователей, указанных в письмах\n",
    "    name = re.compile(<your code here>)\n",
    "    res = name.sub(\"\", text)\n",
    "    # Удалите лишние переносы строк и разбейте на предложения по знаку \".\"\n",
    "    res = <your code here>\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive = split_data(positive_plain)\n",
    "negative = split_data(negative_plain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(positive), len(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_labels = [1] * len(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_labels = [0] * len(negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим все в один список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_text = positive + negative\n",
    "all_labels = pos_labels + neg_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предварительный анализ коллекции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Средняя длина предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_data = df[0].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Длины текстов в символах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "n, bins, patches = ax.hist(len_data.tolist())\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Самые частые слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируйте предложения на слова (nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "all_text = [word_tokenize(line) for line in all_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "\n",
    "n_types = []\n",
    "n_tokens = []\n",
    "fd = FreqDist()\n",
    "for line in all_text:\n",
    "    fd.update(line)\n",
    "    n_types.append(len(fd))\n",
    "    n_tokens.append(sum(list(fd.values())))\n",
    "for i in fd.most_common(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Закон Ципфа\n",
    "\n",
    "В любом достаточно большом тексте ранг типа обратно пропорционален его частоте: f=a/r\n",
    "\n",
    "f – частота типа, r – ранг типа, a – параметр, для славянских языков – около 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqs = list(fd.values())\n",
    "freqs = sorted(freqs, reverse = True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs[:300], range(300))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Закон Хипса\n",
    "\n",
    "С увеличением длины текста (количества токенов), количество типов увеличивается в соответствии с законом: |V|=K∗N^b\n",
    "\n",
    "N – число токенов, |V| – количество типов в словаре, K,b – параметры, обычно K∈[10,100],b∈[0.4,0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_types, n_tokens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовим данные для nltk.NaiveBayesClassifier\n",
    "\n",
    "Классификатор принимает данные о предложении в виде словаря {\"слово\": #количество встреч в предожении}\n",
    "\n",
    "Используйсте Counter. Пример работы:\n",
    "\n",
    "Counter('abracadabra')\n",
    "\n",
    ">Counter({'a': 5, 'b': 2, 'c': 1, 'd': 1, 'r': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text = <your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import NaiveBayesClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_text, all_labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = NaiveBayesClassifier.train(zip(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Протестируем качество классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = clf.classify_many(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавим признаков\n",
    "\n",
    "Для каждого примера добавим количество частей речи в нем. Если мы встретили знак пунктуации, то обозначим его как 'PNCT'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.analyzer.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте pymorphy2.analyzer.MorphAnalyzer.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_text_with_pos = []\n",
    "for sample in all_text:\n",
    "    update = Counter(sample)\n",
    "    for word, count in sample.items():\n",
    "        <your code here>\n",
    "    all_text_with_pos.append(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(all_text_with_pos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_text_with_pos, all_labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = NaiveBayesClassifier.train(zip(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = clf.classify_many(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем лемматизировать слова\n",
    "\n",
    "Обучите тот же классификатор но на примерах, где все слова в нормальной форме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text_with_pos = []\n",
    "for sample in all_text:\n",
    "    update = Counter()\n",
    "    for word, count in sample.items():\n",
    "        <your code here>\n",
    "    all_text_with_pos.append(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_text_with_pos, all_labels, test_size=0.1)\n",
    "clf = NaiveBayesClassifier.train(zip(X_train, y_train))\n",
    "\n",
    "pred = clf.classify_many(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как изменилось качество? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Использование знаний морфологии для генерации текста\n",
    "\n",
    "Задание: написать шаблон вида: {person} {action} {count} {target}. Где\n",
    "\n",
    "Person - лицо которое выполняет действие action. Каждое такое действие может быть в трех временах (настоящее, прошедшее и будущее). Действие выполняется с целью target. Такая цель - это некоторый объект или объекты числом count. count>0.\n",
    "\n",
    "Используйте make_agree_with_number, parse и inflect из библиотеки pymorphy2.\n",
    "\n",
    "Времена глаголов в документации pymorphy2: past (прошедшее), pres (настоящее), futr (будущее)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.analyzer.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласование существительного с числом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "butyavka = morph.parse(\"бутявка\")[0]\n",
    "butyavka.make_agree_with_number(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы поставить слово в нужную форму используется inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "butyavka.inflect({'gent'})  # нет кого? (родительный падеж)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "butyavka.inflect({'plur', 'gent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genarate(person, action, time, count, target):\n",
    "    # Поставьте action в нужное время\n",
    "    action = <your code here>\n",
    "    # Согласуйте target с числом\n",
    "    target = <your code here>\n",
    "    return \"{person} {action} {count} {target}\".format(person=person, action=action, count=count, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genarate(\"Лиза\", \"съела\", \"past\", 2, \"груша\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Статистические морфологические анализаторы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим данные из nltk.treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = treebank.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выделим признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1]\n",
    "        # Придумайте еще признаков\n",
    "        # <your code here>\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def untag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the dataset for training and testing\n",
    "cutoff = int(.75 * len(sentences))\n",
    "training_sentences = sentences[:cutoff]\n",
    "test_sentences = sentences[cutoff:]\n",
    "\n",
    "\n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    " \n",
    "    for tagged in tagged_sentences:\n",
    "        for index in range(len(tagged)):\n",
    "            X.append(features(untag(tagged), index))\n",
    "            y.append(tagged[index][1])\n",
    " \n",
    "    return X, y\n",
    " \n",
    "X, y = transform_to_dataset(training_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В качестве классификатора используем DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='entropy'))\n",
    "])\n",
    "\n",
    "\n",
    "# Используем не все примеры (может не хватить оперативной памяти или долго обучаться)\n",
    "clf.fit(X[:10000], y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = transform_to_dataset(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.score(X_test[:100], y_test[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классифицируем с помощью CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = sentences[:-100], sentences[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ct = CRFTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ct.train(train ,'model.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ct.evaluate(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
